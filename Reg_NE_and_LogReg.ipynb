{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPq0nx1bYJjpWxztGd3KLLO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ellenwterry/PoliticalAnalysis/blob/main/Reg_NE_and_LogReg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Libraries"
      ],
      "metadata": {
        "id": "yUOsjDzaufik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import patsy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "!pip install nest-asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import patsy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "!pip install pystan==3.7.0\n",
        "#!pip install pystan\n",
        "!pip install corner\n",
        "import stan\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "!pip install geopy\n",
        "from geopy.geocoders import Nominatim\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install pygris\n",
        "# import matplotlib.pyplot as plt\n",
        "from pygris import core_based_statistical_areas\n",
        "from pygris import tracts\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "import geopandas as gpd\n",
        "import folium\n",
        "# from google.colab import files\n"
      ],
      "metadata": {
        "id": "G9vYtDP_eAij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Data"
      ],
      "metadata": {
        "id": "ss-RECEruwjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Get Data from Github ---------- #\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/ellenwterry/PoliticalAnalysis/main/VoteBase.csv'\n",
        "VoteBase = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "nEk2b3mGgIXh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tidy Data"
      ],
      "metadata": {
        "id": "DYdBz2E5u1Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Clean up data ---------- #\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "le.fit(VoteBase['Sex'])\n",
        "\n",
        "codes = {'NR':0, 'M': 1, 'F': 2}\n",
        "VoteBase['Sex'] = VoteBase['Sex'].map(codes)\n",
        "\n",
        "VoteBase['Age']=VoteBase.Age.astype('int32')\n",
        "\n",
        "#VoteBase['LastPrimary'] = le.transform(VoteBase['LastPrimary'])\n",
        "codes = {'NR':0, 'R': 1, 'D':2}\n",
        "VoteBase['LastPrimary'] = VoteBase['LastPrimary'].map(codes)\n",
        "\n",
        "#VoteBase['Education'] = le.transform(VoteBase['Education'])\n",
        "codes = {'NR':0, 'HS': 1, 'Some College':2, 'Bachelor':3, 'Masters':4, 'Doctorate':5}\n",
        "VoteBase['Education'] = VoteBase['Education'].map(codes)\n",
        "\n",
        "#VoteBase['HHIncome'] = le.transform(VoteBase['HHIncome'])\n",
        "codes = {'NR':0, 'Under 50k': 1, '50k-100k':2, '100k-200k':3, '200k-300k':4, '300k-500k':5, 'Over 500k':6}\n",
        "VoteBase['HHIncome'] = VoteBase['HHIncome'].map(codes)\n",
        "\n",
        "#VoteBase['ReligiousAffil'] = le.transform(VoteBase['ReligiousAffil'])\n",
        "codes = {'NR':0,'Protestant': 1, 'Catholic':2, 'Other':3, 'None':4}\n",
        "VoteBase['ReligiousAffil'] = VoteBase['ReligiousAffil'].map(codes)\n",
        "\n",
        "#VoteBase['Support24'] = le.transform(VoteBase['Support24'])\n",
        "codes = {'R':0, 'D': 1}\n",
        "VoteBase['Support24'] = VoteBase['Support24'].map(codes)\n",
        "# NOTE: NAs were excluded from sample so that algorithms could score using logistic scale - 2nd pass will use imputed values\n",
        "\n",
        "#VoteBase['TopIssue'] = le.transform(VoteBase['TopIssue'])\n",
        "codes = {'NR':0, 'RFree':1, 'Parents':2, 'Crime':3, 'Economy':4, 'Womens':5, 'Education':6, 'Environment':7, 'Democracy':8}\n",
        "VoteBase['TopIssue'] = VoteBase['TopIssue'].map(codes)\n",
        "\n",
        "# This is for the second data source (later)\n",
        "codes = {'NS':0, 'NR':1,'Signed':2}\n",
        "VoteBase['RRPetition'] = VoteBase['RRPetition'].map(codes)"
      ],
      "metadata": {
        "id": "bOha1ArygIhY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into Training and Test Sets"
      ],
      "metadata": {
        "id": "ELXUZnIou9DK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#np.random.randint(0, 10, size=4)\n",
        "rows = VoteBase.shape[0]-1\n",
        "testInd = np.random.randint(0, (VoteBase.shape[0]-1), size=100)\n",
        "tstBase = VoteBase[VoteBase.index.isin(testInd)]\n",
        "trainBase = VoteBase[~VoteBase.index.isin(tstBase)]\n"
      ],
      "metadata": {
        "id": "VhvBvipmJi7B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yTrain = trainBase['Support24']\n",
        "yTest = tstBase['Support24']\n",
        "Xmatrix = patsy.dmatrix('Age + Sex + Education + HHIncome+ ReligiousAffil + LastPrimary + TopIssue', trainBase)\n",
        "tstMatrix = patsy.dmatrix('Age + Sex + Education + HHIncome+ ReligiousAffil + LastPrimary + TopIssue', tstBase)\n",
        "rows = Xmatrix.shape[0]\n",
        "columns = Xmatrix.shape[1]\n",
        "rows, columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEEzs2WbgXqt",
        "outputId": "c09a1bec-d67c-4372-b411-f5191bb2c99d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2498, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train LogReg Model"
      ],
      "metadata": {
        "id": "g5WoIiVg7Iki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(solver='sag')\n",
        "model.fit(Xmatrix, yTrain)\n",
        "Pred = model.predict(Xmatrix)\n",
        "Probs = pd.DataFrame(model.predict_proba(tstMatrix))\n",
        "theta = np.matrix(model.coef_)\n",
        "intercept = model.intercept_\n",
        "Probs[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpRrP2aqgX0C",
        "outputId": "2e5c22a4-973e-47ff-bfe8-d588ee76fdcd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0.858282\n",
              "1     0.103621\n",
              "2     0.153021\n",
              "3     0.097443\n",
              "4     0.111529\n",
              "        ...   \n",
              "95    0.966573\n",
              "96    0.562737\n",
              "97    0.993304\n",
              "98    0.946382\n",
              "99    0.966409\n",
              "Name: 1, Length: 100, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select Test Samples and Confirm using Equation."
      ],
      "metadata": {
        "id": "7Y4vLTFUv5pE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stable_sigmoid(x):\n",
        "  # Using np.where to avoid numerical overflow or underflow.\n",
        "  return np.where(x >= 0, 1 / (1 + np.exp(-x)), np.exp(x) / (1 + np.exp(x)))\n",
        "\n",
        "# This logreg algorithm breaks out the bias separately for analysis with multinomials.\n",
        "\n",
        "Prob2 = stable_sigmoid((np.dot(model.coef_,tstMatrix[0].transpose())+ model.intercept_).transpose())\n",
        "Prob2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN4HzVnImVYb",
        "outputId": "024ce440-832e-44eb-b7b8-e5b27366e39c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.85828241])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}